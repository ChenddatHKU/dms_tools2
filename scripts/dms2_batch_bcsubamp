#!python

"""Runs a batch of ``dms2_bcsubamp`` programs, summarizes results."""


import os
import glob
import sys
import re
import logging
import functools
import subprocess
import multiprocessing
import multiprocessing.dummy
import pandas
import dms_tools2.parseargs
import dms_tools2.utils
import dms_tools2.plot


def main():
    """Main body of script."""

    parser = dms_tools2.parseargs.batch_bcsubampParser()
    args = vars(parser.parse_args())
    prog = parser.prog

    # set up names of output files
    assert re.search('^[a-zA-Z0-9\-]+$', args['summaryprefix']), \
            "--summaryprefix should contain only letters, numbers, and dashes"
    if args['outdir']:
        if not os.path.isdir(args['outdir']):
            os.mkdir(args['outdir'])
    else:
        args['outdir'] = ''
    filesuffixes = {
            'log':'.log',
            'readstats':'_readstats.pdf',
            'bcstats':'_bcstats.pdf',
            }
    files = dict([(f, os.path.join(args['outdir'], '{0}{1}'.format(
            args['summaryprefix'], s))) for (f, s) in filesuffixes.items()])

    # do we need to proceed
    if args['use_existing'] == 'yes' and all(map(
                os.path.isfile, files.values())):
            print("Output summary files already exist and '--use_existing' "
                    "is 'yes', so exiting with no further action.")
            sys.exit(0)

    logger = dms_tools2.utils.initLogger(files['log'], prog, args)

    # log in try / except / finally loop
    try:

        for f in files:
            if os.path.isfile(f):
                logger.info("Removing existing file {0}".format(f))
                os.remove(f)

        # read batchfile, strip any whitespace from strings
        logger.info("Parsing sample info from {0}".format(args['batchfile']))
        assert os.path.isfile(args['batchfile']), "no batchfile"
        batchruns = pandas.read_csv(args['batchfile'])
        batchruns.columns = batchruns.columns.str.strip()
        colnames = set(['name', 'R1', 'plotgroup'])
        assert set(batchruns.columns) >= colnames, ("batchfile lacks "
                "required column names of: {0}".format(', '.join(colnames)))
        for c in batchruns.columns:
            batchruns[c] = (batchruns[c].map(str).map(str.strip).
                    replace('nan', ''))
        logger.info("Read the following sample information:\n{0}\n".format(
                batchruns.to_csv(index=False)))
        assert len(batchruns['name']) == len(set(batchruns['name'].values)),\
                "Duplicated name"

        # determine how many cpus to use
        if args['ncpus'] == -1:
            ncpus = multiprocessing.cpu_count()
        elif args['ncpus'] > 0:
            ncpus = min(args['ncpus'], multiprocessing.cpu_count())
        else:
            raise ValueError("--ncpus must be -1 or > 0")

        # run dms2_bcsubamp for each sample in batchfile
        logger.info("Running dms2_bcsubamp on all samples using "
                "{0} CPUs...".format(ncpus))
        argslist = []
        for (i, row) in batchruns.iterrows():
            # define newargs to pass to dms2_bcsubamp
            newargs = ['dms2_bcsubamp', '--name', row['name'], 
                    '--R1', row['R1']]
            for (arg, val) in args.items():
                if arg in ['batchfile', 'ncpus', 'summaryprefix']:
                    continue
                elif val:
                    newargs.append('--{0}'.format(arg))
                    if isinstance(val, list):
                        newargs += map(str, val)
                    else:
                        newargs.append(str(val))
            argslist.append(newargs)
        pool = multiprocessing.dummy.Pool(ncpus)
        pool.imap(functools.partial(subprocess.check_output, 
                stderr=subprocess.STDOUT), argslist)
        pool.close()
        pool.join()
        logger.info("Completed runs of dms2_bcsubamp.\n")

        # define dms2_bcsubamp output files and make sure they exist 
        for (filename, filesuffix) in [
                ('counts', '_{0}counts.csv'.format(args['chartype'])),
                ('readstats', '_readstats.csv'),
                ('readsperbc', '_readsperbc.csv'),
                ('bcstats', '_bcstats.csv')]:
            batchruns[filename] = (args['outdir'] + '/' + batchruns['name'] +
                    filesuffix)
            assert all(map(os.path.isfile, batchruns[filename].values)),\
                    "Did not create all of these files:\n{0}".format(
                    '\n'.join(batchruns[filename].values))

        # make plots for each plot group
        plotgroups = set(batchruns['plotgroup'].values)
        logger.info("Making summary plots for the {0} plotgroups.".format(
                len(plotgroups)))
        for plotgroup in plotgroups:
            if len(plotgroups) > 1:
                logger.info("Plotting for plotgroup: {0}".format(
                    lambda x: x if x else '<empty name>'))
            groupruns = batchruns.loc[batchruns['plotgroup'] == plotgroup]
            logger.info("Plotting read stats to {0}".format(files['readstats']))
            dms_tools2.plot.plotReadStats(groupruns['name'], 
                    groupruns['readstats'], files['readstats'])
            logger.info("Plotting barcode stats to {0}".format(files['bcstats']))
            dms_tools2.plot.plotBCStats(groupruns['name'], 
                    groupruns['bcstats'], files['bcstats'])

    except:
        logger.exception('Terminating {0} with ERROR'.format(prog))
        for (fname, fpath) in files.items():
            if fname != 'log' and os.path.isfile(fpath):
                logger.exception("Deleting file {0}".format(fpath))
                os.remove(fpath)

    else:
        logger.info('Successful completion of {0}'.format(prog))

    finally:
        logging.shutdown()



if __name__ == '__main__':
    main() # run the script
