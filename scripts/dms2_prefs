#!python

"""Aligns and counts mutations in barcoded subamplicons."""


import os
import re
import sys
import logging
import multiprocessing
import natsort
import pandas
from dms_tools2 import CODONS, AAS, AAS_WITHSTOP, CODON_TO_AA
import dms_tools2.utils
import dms_tools2.parseargs
import dms_tools2.prefs



def main():
    """Main body of script."""

    parser = dms_tools2.parseargs.prefsParser()
    args = vars(parser.parse_args())
    prog = parser.prog

    # set up names of output files
    assert re.search('^[a-zA-Z0-9\-]+$', args['name']), \
            "--name should contain only letters, numbers, and dashes"
    if args['outdir']:
        if not os.path.isdir(args['outdir']):
            os.mkdir(args['outdir'])
    else:
        args['outdir'] = ''
    filesuffixes = {
            'log':'.log',
            }
    files = dict([(f, os.path.join(args['outdir'], '{0}{1}'.format(
            args['name'], s))) for (f, s) in filesuffixes.items()])

    # do we need to proceed?
    if args['use_existing'] == 'yes' and all(map(
                os.path.isfile, files.values())):
        print("Output files already exist and '--use_existing' is 'yes', "
              "so exiting with no further action.")
        sys.exit(0)

    logger = dms_tools2.utils.initLogger(files['log'], prog, args)

    # log in try / except / finally loop
    try:

        # remove expected output files if they already exist
        for f in files:
            if os.path.isfile(f):
                logger.info("Removing existing file {0}".format(f))
                os.remove(f)

        # read in the counts files
        if not args['indir']:
            args['indir'] = ''
        else:
            assert os.path.isdir(args['indir']), "No --indir {0}".format(
                    args['indir'])
        if args['chartype']:
            countsuffix = '_codoncounts.csv'
        else:
            raise ValueError("Invalid chartype")
        counts = {}
        for ctype in ['pre', 'post']:
            fname = os.path.join(args['indir'], args[ctype])
            if not os.path.isfile(fname):
                if os.path.isfile(fname + countsuffix):
                    fname = fname + countsuffix
                else:
                    raise ValueError("Missing file for --{0}".format(ctype))
            logger.info("Reading {0}-selection counts from {1}".format(
                    ctype, fname))
            counts[ctype] = pandas.read_csv(fname)
        if args['err']:
            ferr = {}
            for (i, ctype) in enumerate(['pre', 'post']):
                fname = os.path.join(args['indir'], args['err'][i])
                if not os.path.isfile(fname):
                    if os.path.isfile(fname + countsuffix):
                        fname = fname + countsuffix
                    else:
                        raise ValueError("Missing file {0} for --err".format(
                                i + 1))
                ferr[ctype] = fname
            if len(set(map(os.path.realpath, ferr.values()))) == 1:
                error_model = 'same'
                logger.info("Reading error-control counts from {0}"
                        .format(ferr['pre']))
                counts['err'] = pandas.read_csv(ferr['pre'])
            else:
                error_model = 'different'
                for (ctype, f) in ferr.items():
                    logger.info("Reading {0}-selection error-control "
                            "counts from {0}".format(ctype, f))
                    counts['err{0}'.format(ctype)] = pandas.read_csv(f)
        else:
            error_model = 'none'

        # get sites and wildtype identities, sorted by site
        sites = wts = None
        for c in counts.values():
            (csites, cwts) = zip(*natsort.natsorted(zip(
                    c['site'].values, c['wildtype'].values)))
            if sites == wts == None:
                sites = csites
                wts = cwts
            else:
                assert sites == csites, "different sets of sites"
                assert wts == cwts, "different wildtype identities"
        assert len(sites) == len(set(sites)), "non-unique sites"
        logger.info("Read counts for {0} sites.".format(len(sites)))
        logger.info("Here are sites and wildtype identities:\n\t{0}\n".format(
                '\n\t'.join(['{0}\t{1}'.format(r, wt) for (r, wt) in zip(
                sites, wts)])))
        if args['excludestop'] == 'yes' and args['chartype'] == 'codon_to_aa':
            if CODON_TO_AA[wts[-1]] == '*':
                sites = sites[ : -1]
                wts = wts[ : -1]
                logger.info("Excluding the last site as it a stop codon.\n")

        if args['method'] == 'ratio':
            raise ValueError("--method ratio not yet implemented")

        elif args['method'] == 'bayesian':
            logger.info("Setting up for Bayesian inference of the prefs")

            # compute mutation rates for priors
            if args['chartype'] == 'codon_to_aa':
                for ctype in list(counts.keys()):
                    counts[ctype] = dms_tools2.utils.annotateCodonCounts(
                            counts[ctype])
                avgmu = counts['pre'][['mutfreq{0}nt'.format(nmuts + 1) 
                        for nmuts in range(3)]].mean().values.sum()
                if error_model == 'none':
                    logger.info("Average mutation rate:\n\t{0}".format(avgmu))
                elif error_model == 'same':
                    avgepsilon = counts['err'][['mutfreq{0}nt'.format(nmuts + 1) 
                            for nmuts in range(3)]].mean().values
                    avgmu -= avgepsilon.sum()
                    logger.info("Average mutation and error rates:\n\t{0}\n\t{1}"
                            .format(avgmu, avgepsilon))
                elif error_model == 'different':
                    avgepsilon = counts['errpre'][['mutfreq{0}nt'.format(
                            nmuts + 1) for nmuts in range(3)]].mean().values
                    avgmu -= avgepsilon.sum()
                    avgrho = counts['errpost'][['mutfreq{0}nt'.format(
                            nmuts + 1) for nmuts in range(3)]].mean().values
                    logger.info("Average mutation, pre-selection, and post-"
                            "selection error rates:\n\t{0}\n\t{1}\n\t{2}"
                            .format(avgmu, avgepsilon, avgrho))
                else:
                    raise ValueError("invalid error_model")
                assert 0 < avgmu < 1, "Invalid avg mut rate {0}".format(avgmu)
            else:
                raise ValueError("Invalid chartype")

            logger.info("Compiling ``pystan`` model...")
            pystan_error_model = ({
                    'none':dms_tools2.prefs.StanModelNoneErr,
                    'same':dms_tools2.prefs.StanModelSameErr,
                    'different':dms_tools2.prefs.StanModelDifferentErr,
                    }[error_model])()
            logger.info("Completed compiling ``pystan`` model.\n")

            # begin inferring prefs in a multiprocessing pool
            if args['ncpus'] == -1:
                ncpus = multiprocessing.cpu_count()
            else:
                ncpus = min(args['ncpus'], multiprocessing.cpu_count())
            assert ncpus > 0
            pool = multiprocessing.Pool(ncpus)

            for (r, wt) in zip(sites, wts):

                # build counts and priors to pass to `inferSitePrefs`
                rcounts = {}
                priors = {}
                if args['chartype'] == 'codon_to_aa':
                    wtaa = CODON_TO_AA[wt]
                    if args['excludestop'] == 'yes':
                        charlist = AAS
                    elif args['excludestop'] == 'no':
                        charlist = AAS_WITHSTOP
                    else:
                        raise ValueError("Invalid --excludestop")
                    for (ctype, df) in counts.items():
                        aacounts = dms_tools2.utils.codonToAACounts(
                                df[df['site'] == r])
                        rcounts[ctype] = dict(aacounts[charlist].ix[0])
                    priors = {}
                    for prior in ['mur_prior_params', 
                                'epsilonr_prior_params',
                                'rhor_prior_params']:
                        priors[prior] = dict([(aa, 0.0) for aa in charlist])
                        priors[prior][wtaa] = 1.0
                    avgmu_percodon = avgmu / float(len(CODONS))
                    nchars_with_m = dict([(nnt, 0) for nnt in range(4)])
                    for x in CODONS:
                        nnt = sum([xi == wti for (xi, wti) in zip(x, wt)])
                        nchars_with_m[nnt] += 1
                    for x in CODONS:
                        if x == wt:
                            continue
                        aa = CODON_TO_AA[x]
                        if aa == '*' and args['excludestop'] == 'yes':
                            continue
                        priors['mur_prior_params'][aa] += avgmu_percodon
                        priors['mur_prior_params'][wtaa] -= avgmu_percodon
                        nnt = sum([xi == wti for (xi, wti) in zip(x, wt)])
                        if error_model in ['different', 'same']:
                            y = avgepsilon[nnt - 1] / nchars_with_m[nnt]
                            priors['epsilonr_prior_params'][aa] += y
                            priors['epsilonr_prior_params'][wtaa] -= y
                        if error_model == 'different':
                            y = avgrho[nnt - 1] / nchars_with_m[nnt]
                            priors['rhor_prior_params'][aa] += y
                            priors['rhor_prior_params'][wtaa] -= y
                else:
                    raise ValueError("Invalid chartype")
                assert all([c > 0 for c in args['conc']])
                (cprefs, cmu, cerr) = args['conc']
                for x in charlist:
                    priors['mur_prior_params'][x] *= len(charlist) * cmu
                    priors['epsilonr_prior_params'][x] *= len(charlist) * cerr
                    priors['rhor_prior_params'][x] *= len(charlist) * cerr
                priors['pir_prior_params'] = dict([(x, cprefs) for x in charlist])

    except:
        logger.exception('Terminating {0} with ERROR'.format(prog))
        for (fname, fpath) in files.items():
            if fname != 'log' and os.path.isfile(fpath):
                logger.exception("Deleting file {0}".format(fpath))
                os.remove(fpath)

    else:
        logger.info('Successful completion of {0}'.format(prog))

    finally:
        logging.shutdown()


if __name__ == '__main__':
    main() # run the script
