#!python

"""Aligns and counts mutations in barcoded subamplicons."""


import os
import sys
import re
import logging
import gzip
import random
import Bio.SeqIO
import dms_tools2.parseargs
import dms_tools2.utils



def main():
    """Main body of script."""

    parser = dms_tools2.parseargs.bcsubampliconsParser()
    args = vars(parser.parse_args())
    prog = parser.prog

    random.seed(args['seed'])

    # set up names of output files
    assert re.search('^[a-zA-Z0-9\-]+$', args['name']), \
            "--name should contain only letters, numbers, and dashes"
    if args['outdir']:
        if not os.path.isdir(args['outdir']):
            os.mkdir(args['outdir'])
    else:
        args['outdir'] = ''
    filesuffixes = {
            'log':'.log',
            'counts':'_counts.csv',
            'summarystats':'_summarystats.csv'
            }
    if args['bcinfo']:
        filesuffixes['bcinfo'] = '_bcinfo.txt.gz'
    files = dict([(f, '{0}/{1}{2}'.format(args['outdir'], args['name'], s))
            for (f, s) in filesuffixes.items()])

    # do we need to proceed?
    if args['use_existing'] and all(map(os.path.isfile, files.values())):
        print("Output files already exist and '--use_existing' specified, "
              "so exiting with no further action.")
        sys.exit(0)

    logger = dms_tools2.utils.initLogger(files['log'], prog, args)

    # log in try / except loop
    try:

        for f in files:
            if os.path.isfile(f):
                logger.info("Removing existing file {0}".format(f))
                os.remove(f)

        assert not (args['purgeread'] and args['purgebc']), ("It does "
                "not make sense to use both --purgeread and --purgebc "
                "as they subsample the data in different ways.")

        # read refseq
        refseq = [s for s in Bio.SeqIO.parse(args['refseq'], 'fasta')]
        assert len(refseq) == 1, "refseq does not specify one sequence" 
        refseq = str(refseq[0].seq).upper()
        if args['chartype'] == 'codon':
            assert re.search('^[{0}]+$'.format(''.join(dms_tools2.NTS)), 
                    refseq), "refseq does not contain only DNA nts"
            assert len(refseq) % 3 == 0, "refseq length not multiple of 3"
            logger.info('Read refseq of {0} codons from {1}'.format(
                    len(refseq), args['refseq']))
        else:
            raise ValueError("Invalid chartype")

        assert args['bclen'] > 0, 'bclen not > 0'

        # check validity of alignspecs
        alignspecs = []
        for s in alignspecs:
            (refseqstart, refseqend, r1start, r2start) = map(int(s.split(',')))
            for (rstart, rname) in [(r1start, 'R1START'), (r2start, 'R2START')]:
                if (args['bclen'] > rstart):
                    raise ValueError("alignspecs has {0} of {1}, which "
                            "doesn't fully trim barcode of bclen {2}".format(
                            rname, rstart, args['bclen']))
                assert rstart >= 1, "{0} must be >= 1".format(rname)
            assert refseqend > refseqstart, "REFSEQEND <= REFSEQSTART"
            assert refseqstart >= 0, "REFSEQSTART < 1"
            assert refseqend <= len(refseq), "REFSEQEND > len(refseq)"
            alignspecs.append((refseqstart, refseqend, r1start, r2start))

        # check on read files
        r1files = args['R1']
        assert all(map(os.path.isfile, r1files)), "Missing R1 files"
        if not args['R2']:
            r2files = []
            for r1 in r1files:
                assert r1.count('_R1') == 1, ("Can't guess R2 file for R1 "
                        "file {0}".format(r1))
                r2files.append(r1.replace('_R1', '_R2'))
        else:
            r2files = args['R2']
            assert len(r1files) == len(r2files), "R1 and R2 must be same length"
        assert all(map(os.path.isfile, r2files)), "Missing R2 files"
        logger.info("Reads are in these FASTQ pairs:\n\t{0}\n".format(
                '\n\t'.join(['{0} and {1}'.format(r1, r2) for (r1, r2) in
                zip(r1files, r2files)])))

        # collect reads by barcode while iterating over reads
        logger.info("Now parsing read pairs...")
        n = {
                'total':0,
                'fail filter':0,
                'low Q barcode':0,
            }
        if args['purgeread']:
            n['reads purged'] = 0
            logger.info("Purging read pairs with probability {0:.3f} to "
                    "subsample the data.".format(args['purgeread']))
        minqchar = chr(args['minq'] + 33) # character for Q score cutoff

        barcodes = {}
        for read_tup in dms_tools2.utils.iteratePairedFASTQ(r1files, r2files):

            if args['purgeread']:
                if random.random() < args['purgeread']:
                    n['reads purged'] += 1
                    continue

            n['total'] += 1
            if n['total'] % 1e5 == 0:
                logger.info("Reads parsed so far: {0}".format(n['total']))

            (name, r1, r2, q1, q2, failfilter) = read_tup

            if failfilter:
                n['fail filter'] += 1
                continue

            r1 = dms_tools2.utils.lowQtoN(r1, q1, minqchar)
            r2 = dms_tools2.utils.lowQtoN(r2, q2, minqchar)

            barcode = r1[ : args['bclen']] + r2[ : args['bclen']]
            if 'N' in barcode:
                n['low Q barcode'] += 1
                continue

            if barcode in barcodes:
                barcodes[barcode].append((r1, r2))
            else:
                barcodes[barcode] = [(r1, r2)]


        logger.info('Parsed {0} reads, found {1} unique barcodes.\n'.format(
                n['total'], len(barcodes)))

        sys.exit(0)

        readcategories.append('barcodes randomly purged')
        if args['purgefrac']:
            logger.info('Randomly purging barcodes with probability %.3f to subsample the data.' % args['purgefrac'])
            npurged = 0
            for barcode in list(barcodes.iterkeys()):
                if random.random() < args['purgefrac']:
                    npurged += 1
                    del barcodes[barcode]
            n['barcodes randomly purged'] = npurged
            logger.info('Randomly purged %d of the %d barcodes (%.1f%%), leaving %d barcodes.\n' % (npurged, len(barcodes) + npurged, 100.0 * npurged / (npurged + len(barcodes)), len(barcodes)))
        else:
            n['barcodes randomly purged'] = 0

        # Examine barcodes to see if they pass criteria, if so align them and record mutation counts
        # Set up *counts* as dict that will hold mutation counts in format for dms_tools.file_io.WriteDMSCounts
        counts = {}
        if args['chartype'] == 'codon':
            for r in range(1, len(refseq) // 3 + 1):
                counts[str(r)] = dict([('WT', refseq[3 * r - 3 : 3 * r])] + [(codon, 0) for codon in dms_tools.codons])
        else:
            raise ValueError("Invalid chartype %s" % args['chartype'])
        # Now start looping over barcodes
        logger.info('Now examining the %d barcodes to see if reads meet criteria for retention' % len(barcodes))
        newreadcategories = []
        unalignedkeystring = 'un-alignable barcodes with %d reads'
        alignedkeystring = 'aligned barcodes with %d reads'
        discardedkeystring = 'discarded barcodes with %d reads'
        ibarcode = 0
        for barcode in list(barcodes.iterkeys()):
            ibarcode += 1
            if ibarcode % 1e5 == 0:
                logger.info('Barcodes examined so far: %s' % ibarcode)
            nreads = len(barcodes[barcode])
            if nreads < args['minreadsperbarcode']:
                if args['barcodeinfo']:
                    barcodeinfofile.write('BARCODE: %s\nRETAINED: no\nDESCRIPTION: too few reads\nCONSENSUS: none\nREADS:\n\t%s\n\n' % (barcode, '\n\t'.join(['R1 = %s; R2 = %s' % tup for tup in barcodes[barcode]])))
                keystring = discardedkeystring % nreads
            else:
                consensus = dms_tools.utils.BuildReadConsensus(barcodes[barcode], args['minreadidentity'], args['minreadconcurrence'], args['maxreadtrim'], use_cutils=True)
                if consensus:
                    # try to align subamplicon
                    (r1, r2) = consensus
                    for (refseqstart, refseqend, r1start, r2start) in args['alignspecs']:
                        maxN = int(args['maxlowqfrac'] * min(refseqend - refseqstart + 1, len(r1) + len(r2) - r1start - r2start + 2))
                        if r1start >= len(r1) or r2start >= len(r2):
                            aligned = False # reads too short toa align
                        elif not args['R1_is_antisense']:
                            aligned = dms_tools.utils.AlignSubamplicon(refseq, r1[r1start - 1 : ], r2[r2start - 1 : ], refseqstart, refseqend, args['maxmuts'], maxN, args['chartype'], counts, use_cutils=True)
                        else:
                            aligned = dms_tools.utils.AlignSubamplicon(refseq, r2[r2start - 1 : ], r1[r1start - 1 : ], refseqstart, refseqend, args['maxmuts'], maxN, args['chartype'], counts, use_cutils=True)
                        if aligned:
                            keystring = alignedkeystring % nreads
                            if args['barcodeinfo']:
                                barcodeinfofile.write('BARCODE: %s\nRETAINED: yes\nDESCRIPTION: aligned from %d to %d with %d %s mutations\nCONSENSUS: R1 = %s; R2 = %s\nREADS:\n\t%s\n\n' % (barcode, refseqstart, refseqend, aligned[1], args['chartype'], r1, r2, '\n\t'.join(['R1 = %s; R2 = %s' % tup for tup in barcodes[barcode]])))
                            break
                    else:
                        keystring = unalignedkeystring % nreads
                        if args['barcodeinfo']:
                            barcodeinfofile.write('BARCODE: %s\nRETAINED: no\nDESCRIPTION: subamplicon could not be aligned to refseq\nCONSENSUS: R1 = %s; R2 = %s\nREADS:\n\t%s\n\n' % (barcode, r1, r2, '\n\t'.join(['R1 = %s; R2 = %s' % tup for tup in barcodes[barcode]])))
                else:
                    if args['barcodeinfo']:
                        barcodeinfofile.write('BARCODE: %s\nRETAINED: no\nDESCRIPTION: reads not sufficiently identical\nCONSENSUS: none\nREADS:\n\t%s\n\n' % (barcode, '\n\t'.join(['R1 = %s; R2 = %s' % tup for tup in barcodes[barcode]])))
                    keystring = discardedkeystring % nreads
            try:
                n[keystring] += 1
            except KeyError:
                n[keystring] = 1
                newreadcategories.append((nreads, keystring))
            del barcodes[barcode] # free up memory as we finish with barcodes
        newreadcategories.sort()
        readcategories = readcategories + [tup[1] for tup in newreadcategories]
        logger.info('Finished examining all %d barcodes\n' % ibarcode)

        # Write the counts
        logger.info('Writing the %s counts to %s' % (args['chartype'], countsfilename))
        dms_tools.file_io.WriteDMSCounts(countsfile, counts)

        # Summarize statistics
        logger.info('Here are the summary statistics (these are also being written to %s):\n%s' % (summarystatsfilename, '\n'.join(['\t%s = %s' % (category, n[category]) for category in readcategories])))
        summarystatsfile.write('\n'.join(['%s = %s' % (category, n[category]) for category in readcategories]))

    except:
        logger.exception('Terminating {0} with ERROR'.format(prog))
        for (fname, fpath) in files.items():
            if fname != 'log' and os.path.isfile(fpath):
                logger.exception("Deleting file {0}".format(fpath))
                os.remove(fpath)

    else:
        logger.info('Successful completion of {0}'.format(prog))

    finally:
        logging.shutdown()


if __name__ == '__main__':
    main() # run the script
